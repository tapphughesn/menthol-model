{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from tabulate import tabulate\n",
    "printtab = lambda x : print(tabulate(x, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to get the prevalences of the smoking groups in the years 2016 (start), 2021, 2026, 2031, 2051\n",
    "\n",
    "\n",
    "With 95% confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/nick/Documents/Gillings_work/uncertainty_analysis_data/uncertainty_analysis_2025-01-26_21-46-33-428563\"\n",
    "base_dir = \"/Users/nick/Documents/Gillings_work/uncertainty_analysis_data/uncertainty_analysis_2025-01-26_21-56-11-784789\"\n",
    "base_dir = \"/Users/nick/Documents/Gillings_work/uncertainty_analysis_data/uncertainty_analysis_2025-01-27_20-07-10-667648\"\n",
    "base_dir = \"/Users/nick/Documents/Gillings_work/uncertainty_analysis_data/uncertainty_analysis_2025-02-04_21-13-42-395157\"\n",
    "base_dir = \"/Users/nick/Documents/Gillings_work/uncertainty_analysis_data/uncertainty_analysis_2025-04-21_18-34-20-047126\"\n",
    "base_dir = \"/Users/nick/Documents/Gillings_work/uncertainty_analysis_data/uncertainty_analysis_2025-07-22_15-08-21-725343\"\n",
    "output_dir = os.path.join(base_dir, \"outputs\")\n",
    "outputs_dirs = [os.path.join(output_dir, f\"option_{i}\") for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(base_dir, \"outputs\")\n",
    "outputs_dirs = [os.path.join(output_dir, f\"option_{i}\") for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2016\n",
    "years = [2016,2024,2025,2026,2027,2030,2035,2055]\n",
    "year_inds = list(np.array(years) - start_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 8, 9, 10, 11, 14, 19, 39]\n",
      "19\n",
      "[0, 8, 9, 10, 11, 14, 19]\n"
     ]
    }
   ],
   "source": [
    "print(year_inds)\n",
    "print(year_inds[-2])\n",
    "print(year_inds[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_list_options = []\n",
    "SQ_rates = [] # status quo 2031 rates in separate list for comparison\n",
    "\n",
    "for opt in range(6):\n",
    "    outputs = outputs_dirs[opt]\n",
    "    if not os.path.exists(outputs):\n",
    "        continue\n",
    "    collection_list = []\n",
    "\n",
    "    # for each arr, store a 2D array in the list\n",
    "    # axis = 0 are the groups: menthol, nonmenthol, smoker, ecig/dual, former, never (3, 4, 3+4, 5, 2, 1)\n",
    "    # axis = 1 are the years 2016, 2024, 2029, 2034, 2054\n",
    "    for i,f in enumerate(sorted(glob(outputs + \"/*.npy\"))):\n",
    "        arr = np.load(f)\n",
    "        arr = arr[:,:,:,0,:] # age-restrict 18-64\n",
    "        arr = arr[year_inds] # get the years we are interested in\n",
    "        arr = np.sum(arr, axis=(1,2)) # dont care about demographics\n",
    "        arr = arr[:,:-1] # don't need dead people\n",
    "        sums = np.sum(arr, axis=1) # total count for each year\n",
    "        arr = arr / sums[:,np.newaxis] # get proportions\n",
    "        arr = arr.T # transpose so we have (smoking groups, years) as axes\n",
    "        arr = np.concatenate([ # want to add the smokers together too\n",
    "            arr[0:4],\n",
    "            (arr[2] + arr[3])[np.newaxis, :],\n",
    "            arr[4][np.newaxis, :],\n",
    "        ], axis=0)\n",
    "        arr = arr[[2,3,4,5,1,0]] # re-order the smoking groups\n",
    "        # add change 2016-2031 column and change from SQ column\n",
    "        if opt == 0:\n",
    "            SQ_rates.append(arr[:,-2]) # store the status quo rates in the second-to-last year\n",
    "            arr = np.concatenate([\n",
    "                arr[:,:-1], # all years except the last one (2055)\n",
    "                (arr[:,-2] - arr[:,0])[:,np.newaxis], # change from the first year to the second-to-last year\n",
    "                np.zeros((len(arr), 1)), # change from SQ (zeros)\n",
    "                arr[:,-1][:,np.newaxis], # last year\n",
    "            ],axis=1)\n",
    "        else:\n",
    "            arr = np.concatenate([\n",
    "                arr[:,:-1], # all years except the last\n",
    "                (arr[:,-2] - arr[:,0])[:,np.newaxis], # change from the first year to the second-to-last year\n",
    "                ((arr[:,-2] - SQ_rates[i]) / SQ_rates[i])[:,np.newaxis], # change from SQ\n",
    "                arr[:,-1][:,np.newaxis], #last year\n",
    "            ],axis=1)\n",
    "        collection_list.append(arr)\n",
    "\n",
    "\n",
    "    collection_list_options.append(collection_list)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "Smoking Rates, Ban Scenario #0, with 95% Confidence Intervals\n",
      "** Status Quo Scenario **\n",
      "                    2016                       2024                       2025                       2026                      2027                       2030                       2035                       Change 2016-2035           % Change From SQ 2035    2055\n",
      "------------------  -------------------------  -------------------------  -------------------------  ------------------------  -------------------------  -------------------------  -------------------------  -------------------------  -----------------------  -------------------------\n",
      "menthol             5.675%, (5.64, 5.699)      5.741%, (5.513, 5.978)     5.654%, (5.426, 5.891)     5.577%, (5.345, 5.812)    5.502%, (5.272, 5.736)     5.328%, (5.105, 5.558)     5.149%, (4.936, 5.368)     -0.526%, (-0.741, -0.307)  0.0%, (0.0, 0.0)         4.617%, (4.459, 4.778)\n",
      "nonmenthol          9.256%, (9.233, 9.292)     4.933%, (4.676, 5.196)     4.761%, (4.503, 5.021)     4.626%, (4.369, 4.888)    4.523%, (4.273, 4.78)      4.312%, (4.076, 4.549)     4.18%, (3.956, 4.403)      -5.077%, (-5.302, -4.85)   0.0%, (0.0, 0.0)         3.852%, (3.702, 4.002)\n",
      "menthol+nonmenthol  14.932%, (14.931, 14.932)  10.674%, (10.338, 11.009)  10.415%, (10.079, 10.749)  10.203%, (9.871, 10.532)  10.024%, (9.696, 10.355)   9.64%, (9.33, 9.955)       9.329%, (9.024, 9.632)     -5.603%, (-5.908, -5.299)  0.0%, (0.0, 0.0)         8.469%, (8.259, 8.683)\n",
      "ecig/dual           3.741%, (3.696, 3.77)      1.762%, (1.634, 1.897)     1.732%, (1.606, 1.864)     1.714%, (1.592, 1.842)    1.698%, (1.575, 1.825)     1.673%, (1.558, 1.794)     1.654%, (1.548, 1.764)     -2.087%, (-2.199, -1.968)  0.0%, (0.0, 0.0)         1.625%, (1.537, 1.713)\n",
      "former              20.185%, (19.983, 20.303)  29.406%, (28.935, 29.863)  30.025%, (29.562, 30.488)  30.58%, (30.106, 31.056)  31.101%, (30.626, 31.576)  32.275%, (31.799, 32.751)  34.081%, (33.626, 34.54)   13.895%, (13.424, 14.394)  0.0%, (0.0, 0.0)         36.848%, (36.518, 37.177)\n",
      "nonsmoker           61.142%, (61.035, 61.329)  58.158%, (57.76, 58.551)   57.827%, (57.413, 58.224)  57.504%, (57.07, 57.921)  57.177%, (56.728, 57.607)  56.413%, (55.98, 56.852)   54.936%, (54.501, 55.364)  -6.205%, (-6.668, -5.761)  0.0%, (0.0, 0.0)         53.058%, (52.749, 53.363)\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "blah\n"
     ]
    }
   ],
   "source": [
    "status_quo_prevalences = []\n",
    "for opt in range(6):\n",
    "    # analyze collection_list and get 95% confidence intervals\n",
    "    if opt >= len(collection_list_options):\n",
    "        continue\n",
    "    collection_list = np.array(collection_list_options[opt])\n",
    "\n",
    "    mean_results = np.zeros_like(collection_list[0])\n",
    "    upper_bound = np.zeros_like(collection_list[0])\n",
    "    lower_bound = np.zeros_like(collection_list[0])\n",
    "\n",
    "    for i in range(collection_list.shape[1]):\n",
    "        for j in range(collection_list.shape[2]):\n",
    "            mean = np.mean(collection_list[:,i,j])\n",
    "            upper = np.percentile(collection_list[:,i,j], 97.5)\n",
    "            lower = np.percentile(collection_list[:,i,j], 2.5)\n",
    "\n",
    "            mean_results[i,j] = mean\n",
    "            upper_bound[i,j] = upper\n",
    "            lower_bound[i,j] = lower\n",
    "\n",
    "    # do a table\n",
    "\n",
    "    mean_results = np.around(mean_results * 100, decimals=3)\n",
    "    upper_bound = np.around(upper_bound * 100, decimals=3)\n",
    "    lower_bound = np.around(lower_bound * 100, decimals=3)\n",
    "\n",
    "    # change_in_prevalence = np.around(change_in_prevalence * 100, decimals=1)\n",
    "\n",
    "    # header = [\"\", \"2016\", \"2024\", \"2029\", \"2034\", \"Change 2016-2034\", \"% Change from SQ 2034\", \"2054\"]\n",
    "    header = [\"\"] + [str(year) for year in years[:-1]]\n",
    "    header += [f\"Change {years[0]}-{years[-2]}\"]\n",
    "    header += [f\"% Change From SQ {years[-2]}\"] \n",
    "    header += [str(years[-1])]\n",
    "    r1 = [\"menthol\"] + [f\"{mean}%, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "        mean_results[0], upper_bound[0], lower_bound[0]\n",
    "    )]\n",
    "    r2 = [\"nonmenthol\"] + [f\"{mean}%, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "        mean_results[1], upper_bound[1], lower_bound[1]\n",
    "    )]\n",
    "    r3 = [\"menthol+nonmenthol\"] + [f\"{mean}%, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "        mean_results[2], upper_bound[2], lower_bound[2]\n",
    "    )]\n",
    "    r4 = [\"ecig/dual\"] + [f\"{mean}%, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "        mean_results[3], upper_bound[3], lower_bound[3]\n",
    "    )]\n",
    "    r5 = [\"former\"] + [f\"{mean}%, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "        mean_results[4], upper_bound[4], lower_bound[4]\n",
    "    )]\n",
    "    r6 = [\"nonsmoker\"] + [f\"{mean}%, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "        mean_results[5], upper_bound[5], lower_bound[5]\n",
    "    )]\n",
    "\n",
    "    rows = [r1, r2, r3, r4, r5, r6]\n",
    "\n",
    "    tab = [header] + rows\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(f\"Smoking Rates, Ban Scenario #{opt}, with 95% Confidence Intervals\")\n",
    "    if opt == 0: print(\"** Status Quo Scenario **\")\n",
    "    printtab(tab)\n",
    "\n",
    "    for i in range((100)):\n",
    "        print(\"blah\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now get the same table in an easy CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV values to be read into software\n",
      "All values in this table are percentages\n",
      "There are 5 ban scenarios each with a table here\n",
      "In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\n",
      "SQ = Status Quo scenario\n",
      "All numbers are rounded to 5 decimal places which should be more than we want for the final table\n",
      " \n",
      " \n",
      "Smoking Rates, Ban Scenario #0, with 95% Confidence Intervals\n",
      "** Status Quo Scenario **\n",
      "-------------------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ------------------  -------------------  -------------------  -------------------  --------------------  --------------------  ---------  ---------  ---------  ---------  ---------  ---------  ----  ----  ----  ---------  ---------  ---------\n",
      "group,               2016M,     2016LB,    2016UB,    2024M,     2024LB,    2024UB,    2026M,     2026LB,    2026UB,    2034M,     2034LB,    2034UB,    %Change2016-2034M,  %Change2016-2034LB,  %Change2016-2034UB,  %ChangeFromSQ2034M,  %ChangeFromSQ2034LB,  %ChangeFromSQ2034UB,  2054M,     2054LB,    2054UB,\n",
      "menthol,             5.67542,   5.64032,   5.69868,   5.74129,   5.51339,   5.97752,   5.65416,   5.42551,   5.89126,   5.57679,   5.3448,    5.81195,   5.50166,            5.27215,             5.73582,             5.328,               5.10549,              5.55799,              5.14911,   4.93555,   5.36805,   -0.52631,  -0.74062,  -0.30737,  0.0,  0.0,  0.0,  4.61729,   4.45878,   4.77792,\n",
      "nonmenthol,          9.25627,   9.23322,   9.29165,   4.93315,   4.67585,   5.19622,   4.76101,   4.50288,   5.02128,   4.62595,   4.36926,   4.88771,   4.52267,            4.27327,             4.77987,             4.31185,             4.07569,              4.5488,               4.17956,   3.95612,   4.40318,   -5.07671,  -5.30216,  -4.8503,   0.0,  0.0,  0.0,  3.85187,   3.7016,    4.0016,\n",
      "menthol+nonmenthol,  14.93169,  14.93078,  14.93214,  10.67445,  10.33793,  11.00883,  10.41517,  10.07902,  10.74901,  10.20274,  9.871,     10.53233,  10.02433,           9.69649,             10.35475,            9.63985,             9.32993,              9.95525,              9.32867,   9.02352,   9.63205,   -5.60302,  -5.90803,  -5.29935,  0.0,  0.0,  0.0,  8.46916,   8.25936,   8.68259,\n",
      "ecig/dual,           3.74117,   3.69615,   3.76969,   1.76184,   1.63365,   1.89662,   1.73209,   1.60579,   1.86403,   1.7138,    1.59201,   1.84244,   1.69786,            1.57516,             1.8252,              1.67252,             1.55793,              1.79395,              1.65411,   1.54757,   1.76421,   -2.08707,  -2.19948,  -1.96832,  0.0,  0.0,  0.0,  1.6254,    1.53748,   1.71347,\n",
      "former,              20.18539,  19.9826,   20.30312,  29.40559,  28.93508,  29.86277,  30.02542,  29.56195,  30.48787,  30.5799,   30.10609,  31.05586,  31.10128,           30.62573,            31.57635,            32.27481,            31.79862,             32.75128,             34.08075,  33.62593,  34.54027,  13.89536,  13.42386,  14.39358,  0.0,  0.0,  0.0,  36.84792,  36.51767,  37.17667,\n",
      "neversmoker,         61.14174,  61.03511,  61.32883,  58.15812,  57.76003,  58.55125,  57.82732,  57.41286,  58.22414,  57.50356,  57.07046,  57.9211,   57.17653,           56.72784,            57.60678,            56.41282,            55.98005,             56.8516,              54.93647,  54.50108,  55.36391,  -6.20527,  -6.66766,  -5.76086,  0.0,  0.0,  0.0,  53.05753,  52.74932,  53.36328,\n",
      "-------------------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ------------------  -------------------  -------------------  -------------------  --------------------  --------------------  ---------  ---------  ---------  ---------  ---------  ---------  ----  ----  ----  ---------  ---------  ---------\n"
     ]
    }
   ],
   "source": [
    "print(\"CSV values to be read into software\")\n",
    "print(\"All values in this table are percentages\")\n",
    "print(\"There are 5 ban scenarios each with a table here\")\n",
    "print(\"In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\")\n",
    "print(\"SQ = Status Quo scenario\")\n",
    "print(\"All numbers are rounded to 5 decimal places which should be more than we want for the final table\")\n",
    "status_quo_prevalences = []\n",
    "for opt in range(6):\n",
    "    # analyze collection_list and get 95% confidence intervals\n",
    "    if opt >= len(collection_list_options):\n",
    "        continue\n",
    "    collection_list = np.array(collection_list_options[opt])\n",
    "\n",
    "    mean_results = np.zeros_like(collection_list[0])\n",
    "    upper_bound = np.zeros_like(collection_list[0])\n",
    "    lower_bound = np.zeros_like(collection_list[0])\n",
    "\n",
    "    for i in range(collection_list.shape[1]):\n",
    "        for j in range(collection_list.shape[2]):\n",
    "            mean = np.mean(collection_list[:,i,j])\n",
    "            upper = np.percentile(collection_list[:,i,j], 97.5)\n",
    "            lower = np.percentile(collection_list[:,i,j], 2.5)\n",
    "\n",
    "            mean_results[i,j] = mean\n",
    "            upper_bound[i,j] = upper\n",
    "            lower_bound[i,j] = lower\n",
    "\n",
    "\n",
    "    # do a table\n",
    "\n",
    "    mean_results = np.around(mean_results * 100, decimals=5)\n",
    "    upper_bound = np.around(upper_bound * 100, decimals=5)\n",
    "    lower_bound = np.around(lower_bound * 100, decimals=5)\n",
    "\n",
    "    # change_in_prevalence = np.around(change_in_prevalence * 100, decimals=5)\n",
    "\n",
    "    header = [\"2016\", \"2024\", \"2026\", \"2034\", \"%Change2016-2034\", \"%ChangeFromSQ2034\", \"2054\"]\n",
    "    new_header = [\"group,\"]\n",
    "    for e in header:\n",
    "        new_header.append(e + \"M,\")\n",
    "        new_header.append(e + \"LB,\")\n",
    "        new_header.append(e + \"UB,\") \n",
    "    \n",
    "    r1 = [\"menthol,\"]\n",
    "    r2 = [\"nonmenthol,\"]\n",
    "    r3 = [\"menthol+nonmenthol,\"]\n",
    "    r4 = [\"ecig/dual,\"]\n",
    "    r5 = [\"former,\"]\n",
    "    r6 = [\"neversmoker,\"]\n",
    "\n",
    "    rows = [r1, r2, r3, r4, r5, r6]\n",
    "    \n",
    "    \n",
    "    for i, r in enumerate(rows):\n",
    "        for m, ub, lb in zip(mean_results[i], upper_bound[i], lower_bound[i]):\n",
    "            rows[i] += [f\"{m},\", f\"{lb},\", f\"{ub},\"]\n",
    "\n",
    "    tab = [new_header] + rows\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(f\"Smoking Rates, Ban Scenario #{opt}, with 95% Confidence Intervals\")\n",
    "    if opt == 0: print(\"** Status Quo Scenario **\")\n",
    "    print(tabulate(tab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now get mortality results!\n",
    "\n",
    "Want to get mortality in the years 2016, 2021, 2026, 2031, 2051\n",
    "\n",
    "with percent change between 2031 and 2016\n",
    "\n",
    "for full population, non-Hispanic Black, poverty, not poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# collection_list_options = []\n",
    "# total_pops_opt_group = []\n",
    "# SQ_mortality_2021_2031 = []\n",
    "\n",
    "# for opt in range(6):\n",
    "#     outputs = outputs_dirs[opt]\n",
    "#     collection_list = []\n",
    "#     this_total_pops = []\n",
    "\n",
    "#     # for each arr, store a 2D array in the list\n",
    "#     # axis = 0 are the groups: full, black, pov, not pov\n",
    "#     # axis = 1 are the years 2016, 2024, 2029, 2034, 2054\n",
    "#     # original dimensions are (year, black, pov, smoking group)\n",
    "#     # now, original dimensions are (year, black, pov, smoking group) # after we decided to add 65+ year olds separately\n",
    "#     for i,f in enumerate(sorted(glob(outputs + \"/*.npy\"))):\n",
    "#         arr = np.load(f)\n",
    "#         # arr = arr.sum(axis=3)\n",
    "#         arr = arr[:,:,:,0,:]\n",
    "\n",
    "#         # set the number of dead people in the first year (2016) to zero\n",
    "#         # and adjust all mortality afterward accordingly\n",
    "#         arr[:,:,:,5] -= arr[0,:,:,5].reshape((-1,2,2))\n",
    "\n",
    "#         total_pop = np.sum(arr[-1])\n",
    "#         total_black = np.sum(arr[-1,1,:,:])\n",
    "#         total_pov = np.sum(arr[-1,:,1,:])\n",
    "#         total_nonpov = np.sum(arr[-1,:,0,:])\n",
    "\n",
    "#         this_total_pops.append([total_pop, total_black, total_pov, total_nonpov])\n",
    "\n",
    "#         arr = arr[[0, 5, 10, 15, 35]] # get the years we are interested in\n",
    "#         arr = arr [:, :, :, 5] # only care about dead people\n",
    "\n",
    "#         arr = np.concatenate([\n",
    "#             (np.sum(arr, axis=(1,2)))[:, np.newaxis], # full pop\n",
    "#             (np.sum(arr[:,1,:], axis=1))[:, np.newaxis], # black\n",
    "#             (np.sum(arr[:,:,1], axis=1))[:, np.newaxis], # pov\n",
    "#             (np.sum(arr[:,:,0], axis=1))[:, np.newaxis], # not pov\n",
    "#         ], axis=1)\n",
    "\n",
    "#         arr = arr.T # now the dims are group, year\n",
    "\n",
    "#         # add the change from SQ column\n",
    "#         if opt == 0:\n",
    "#             SQ_mortality_2021_2031.append(arr[:,4] - arr[:,1])\n",
    "#             arr = np.concatenate([\n",
    "#                 arr,\n",
    "#                 np.zeros((len(arr), 1))\n",
    "#             ], axis=1)\n",
    "#         else:\n",
    "#             arr = np.concatenate([\n",
    "#                 arr,\n",
    "#                 ((arr[:,4] - arr[:,1]) - SQ_mortality_2021_2031[i])[:, np.newaxis],\n",
    "#             ], axis=1)\n",
    "        \n",
    "#         # print(arr.shape)\n",
    "#         # assert False\n",
    "\n",
    "#         collection_list.append(arr)\n",
    "    \n",
    "#     collection_list_options.append(collection_list)\n",
    "\n",
    "#     this_total_pops = np.array(this_total_pops)\n",
    "#     total_pops_opt_group.append(np.mean(this_total_pops, axis=0))\n",
    "\n",
    "# total_pops_opt_group = np.array(total_pops_opt_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(total_pops_opt_group)\n",
    "# print(total_pops_opt_group.shape)\n",
    "\n",
    "# backup = np.copy(total_pops_opt_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQ_2051_mort = None\n",
    "# for opt in range(6):\n",
    "    \n",
    "#     # analyze collection_list and get 95% confidence intervals\n",
    "#     collection_list = np.array(collection_list_options[opt])\n",
    "\n",
    "#     mean_results = np.zeros_like(collection_list[0])\n",
    "#     upper_bound = np.zeros_like(collection_list[0])\n",
    "#     lower_bound = np.zeros_like(collection_list[0])\n",
    "\n",
    "#     for i in range(collection_list.shape[1]):\n",
    "#         for j in range(collection_list.shape[2]):\n",
    "#             mean = np.mean(collection_list[:,i,j])\n",
    "#             upper = np.percentile(collection_list[:,i,j], 97.5)\n",
    "#             lower = np.percentile(collection_list[:,i,j], 2.5)\n",
    "\n",
    "#             mean_results[i,j] = mean\n",
    "#             upper_bound[i,j] = upper\n",
    "#             lower_bound[i,j] = lower\n",
    "\n",
    "#     # do a table\n",
    "\n",
    "#     mean_results = np.around(mean_results / 100000, decimals=1)\n",
    "#     upper_bound = np.around(upper_bound / 100000, decimals=1)\n",
    "#     lower_bound = np.around(lower_bound / 100000, decimals=1)\n",
    "#     # change_cummort = np.around(change_cummort / 100000, decimals=1)\n",
    "#     total_pops = np.around(total_pops_opt_group[opt] / 100000, decimals=1)\n",
    "\n",
    "#     header = [\"\", \"2016\", \"2024\", \"2029\", \"2034\", \"2054\", \"Change from SQ 2024-2054\", \"total living\"]\n",
    "#     r1 = [\"full pop\"] + [f\"{mean}, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "#         mean_results[0], upper_bound[0], lower_bound[0]\n",
    "#     )]\n",
    "#     r2 = [\"black NH\"] + [f\"{mean}, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "#         mean_results[1], upper_bound[1], lower_bound[1]\n",
    "#     )]\n",
    "#     r3 = [\"poverty\"] + [f\"{mean}, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "#         mean_results[2], upper_bound[2], lower_bound[2]\n",
    "#     )]\n",
    "#     r4 = [\"not poverty\"] + [f\"{mean}, ({lower_bound}, {upper_bound})\" for mean, upper_bound, lower_bound in zip(\n",
    "#         mean_results[3], upper_bound[3], lower_bound[3]\n",
    "#     )]\n",
    "\n",
    "#     rows = [r1, r2, r3, r4]\n",
    "\n",
    "#     # put in total pop\n",
    "#     for i, r in enumerate(rows):\n",
    "#         rows[i] += [f\"{total_pops[i]}\"]\n",
    "\n",
    "#     tab = [header] + rows\n",
    "#     print(\"\")\n",
    "#     print(\"\")\n",
    "#     print(f\"Cumulative Mortality (units of 100,000), Ban Scenario #{opt}, with 95% Confidence Intervals\")\n",
    "#     if opt == 0: print(\"** Status Quo Scenario **\")\n",
    "#     printtab(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortality Data in CSV form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"CSV values to be read into software\")\n",
    "# print(\"All values in this table are absolute counts\")\n",
    "# print(\"There are 5 ban scenarios each with a table here\")\n",
    "# print(\"In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\")\n",
    "# print(\"SQ = Status Quo scenario\")\n",
    "# print(\"All numbers are rounded to 10 decimal places which should be more than we want for the final table\")\n",
    "# SQ_2051_mort = None\n",
    "# for opt in range(6):\n",
    "    \n",
    "#     # analyze collection_list and get 95% confidence intervals\n",
    "#     collection_list = np.array(collection_list_options[opt])\n",
    "\n",
    "#     mean_results = np.zeros_like(collection_list[0])\n",
    "#     upper_bound = np.zeros_like(collection_list[0])\n",
    "#     lower_bound = np.zeros_like(collection_list[0])\n",
    "\n",
    "#     for i in range(collection_list.shape[1]):\n",
    "#         for j in range(collection_list.shape[2]):\n",
    "#             mean = np.mean(collection_list[:,i,j])\n",
    "#             upper = np.percentile(collection_list[:,i,j], 97.5)\n",
    "#             lower = np.percentile(collection_list[:,i,j], 2.5)\n",
    "\n",
    "#             mean_results[i,j] = mean\n",
    "#             upper_bound[i,j] = upper\n",
    "#             lower_bound[i,j] = lower\n",
    "\n",
    "#     # # compute reduction in cumulative mortality\n",
    "#     # change_cummort = None\n",
    "#     # if opt == 0:\n",
    "#     #     SQ_2051_mort = np.concatenate([\n",
    "#     #         mean_results[:,-1][:,np.newaxis],\n",
    "#     #         upper_bound[:,-1][:,np.newaxis],\n",
    "#     #         lower_bound[:,-1][:,np.newaxis],\n",
    "#     #     ], axis=1)\n",
    "#     #     change_cummort = np.zeros_like(SQ_2051_mort)\n",
    "#     # else:\n",
    "#     #     change_cummort = np.concatenate([\n",
    "#     #         (mean_results[:,-1] - SQ_2051_mort[:,0])[:,np.newaxis],\n",
    "#     #         (upper_bound[:,-1] - SQ_2051_mort[:,2])[:,np.newaxis],\n",
    "#     #         (lower_bound[:,-1] - SQ_2051_mort[:,1])[:,np.newaxis],\n",
    "#     #     ], axis=1)\n",
    "\n",
    "#     # do a table\n",
    "\n",
    "#     mean_results = np.around(mean_results / 100000, decimals=10)\n",
    "#     upper_bound = np.around(upper_bound / 100000, decimals=10)\n",
    "#     lower_bound = np.around(lower_bound / 100000, decimals=10)\n",
    "#     # change_cummort = np.around(change_cummort / 100000, decimals=10)\n",
    "#     total_pops = np.around(total_pops_opt_group[opt] / 100000, decimals=10)\n",
    "\n",
    "#     header = [\"2016\", \"2024\", \"2029\", \"2034\", \"2054\", \"ChangeFromSQ2024-2054\"]\n",
    "#     new_header = [\"group,\"]\n",
    "#     for e in header:\n",
    "#         new_header.append(e + \"M,\")\n",
    "#         new_header.append(e + \"LB,\")\n",
    "#         new_header.append(e + \"UB,\") \n",
    "#     new_header += [\"totalLiving\"]\n",
    "\n",
    "#     r1 = [\"fullPop,\"]\n",
    "#     r2 = [\"BlackNH,\"]\n",
    "#     r3 = [\"Poverty,\"]\n",
    "#     r4 = [\"NotPoverty,\"]\n",
    "\n",
    "#     rows = [r1, r2, r3, r4]\n",
    "\n",
    "#     for i, r in enumerate(rows):\n",
    "#         for m, ub, lb in zip(mean_results[i], upper_bound[i], lower_bound[i]):\n",
    "#             rows[i] += [f\"{m},\", f\"{lb},\", f\"{ub},\", ]\n",
    "\n",
    "#     # put in total pop\n",
    "#     for i, r in enumerate(rows):\n",
    "#         # rows[i] += [f\"{change_cummort[i,0]},\", f\"{change_cummort[i,2]},\",f\"{change_cummort[i,1]},\"]\n",
    "#         rows[i] += [f\"{total_pops[i]},\"]\n",
    "\n",
    "#     tab = [new_header] + rows\n",
    "#     print(\"\")\n",
    "#     print(\"\")\n",
    "#     print(f\"Cumulative Mortality (units of 100,000), Ban Scenario #{opt}, with 95% Confidence Intervals\")\n",
    "#     if opt == 0: print(\"** Status Quo Scenario **\")\n",
    "#     print(tabulate(tab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation (Status Quo only)\n",
    "\n",
    "BRFSS validation: 2016, 2017, 2021\n",
    "\n",
    "prevalence of never smoker, former smoker, smoker, ecig/dual\n",
    "\n",
    "for total pop, male, female, black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status quo\n",
    "outputs = outputs_dirs[0]\n",
    "collection_list = []\n",
    "\n",
    "# for each arr, store a 2D array in the list\n",
    "for f in sorted(glob(outputs + \"/*.npy\")):\n",
    "    arr = np.load(f)\n",
    "    arr = arr[[0, 1, 5,]] # get the years we are interested in\n",
    "    arr = arr[:,:,:,:-1] # don't need dead people\n",
    "    sums = np.sum(arr, axis=(1,2,3)) # total count for each year\n",
    "    arr = arr / sums[:, np.newaxis, np.newaxis, np.newaxis] # get proportions\n",
    "    collection_list.append(arr)\n",
    "\n",
    "collection_list = np.array(collection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 2, 2, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "# sample, year, black, pov, state\n",
    "print(collection_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_33234/1637153223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# as of 4/30/2024 the below cell is failing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False\n",
    "# as of 4/30/2024 the below cell is failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 3, 1, 6)\n",
      "(125, 3, 1, 6)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 2 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/3756638454.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# combine smokers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mUSpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mUSpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mBpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mBpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 2 with size 1"
     ]
    }
   ],
   "source": [
    "USpop = collection_list[:,:,:,:,:].sum(axis=(2,3))\n",
    "Bpop = collection_list[:,:,1,:,:].sum(axis=2)\n",
    "print(USpop.shape)\n",
    "print(USpop.shape)\n",
    "\n",
    "# combine smokers\n",
    "\n",
    "USpop[:,:,2] += USpop[:,:,3]\n",
    "Bpop[:,:,2] += Bpop[:,:,3]\n",
    "\n",
    "USpop = USpop[:,:,[0,1,2,4]]\n",
    "Bpop = Bpop[:,:,[0,1,2,4]]\n",
    "\n",
    "print(USpop.shape)\n",
    "print(USpop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/379289699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# black population denominator should not be whole population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mBpop\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# black population denominator should not be whole population\n",
    "\n",
    "if np.sum(Bpop, axis=2)[0,0] != 1:\n",
    "    Bpop /= np.sum(Bpop, axis=2)[:,:,np.newaxis]\n",
    "\n",
    "print(np.sum(Bpop, axis=2)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/3926849625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{m}%, ({lb}, {ub})\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "for pop, name in zip([USpop, Bpop], [\"US Population\", \"Black NH Population\"]):\n",
    "\n",
    "    mean_results = np.zeros_like(pop[0])\n",
    "    upper_bound = np.zeros_like(pop[0])\n",
    "    lower_bound = np.zeros_like(pop[0])\n",
    "\n",
    "    for i in range(pop.shape[1]):\n",
    "        for j in range(pop.shape[2]):\n",
    "            mean = np.mean(pop[:,i,j])\n",
    "            upper = np.percentile(pop[:,i,j], 97.5)\n",
    "            lower = np.percentile(pop[:,i,j], 2.5)\n",
    "\n",
    "            mean_results[i,j] = mean\n",
    "            upper_bound[i,j] = upper\n",
    "            lower_bound[i,j] = lower\n",
    "    \n",
    "    # make a table\n",
    "\n",
    "    mean_results = np.around(mean_results * 100, decimals=1)\n",
    "    upper_bound = np.around(upper_bound * 100, decimals=1)\n",
    "    lower_bound = np.around(lower_bound * 100, decimals=1)\n",
    "\n",
    "    header = [\"\", \"2016\", \"2017\", \"2021\"]\n",
    "\n",
    "    r1 = [\"Never Smoker\"]\n",
    "    r2 = [\"Former Smoker\"]\n",
    "    r3 = [\"Cigarette Smoker\"]\n",
    "    r4 = [\"Ecig/Dual\"]\n",
    "\n",
    "    rows = [r1, r2, r3, r4]\n",
    "\n",
    "    for i, r in enumerate(rows):\n",
    "        for m, ub, lb in zip(mean_results[:,i], upper_bound[:,i], lower_bound[:,i]):\n",
    "            rows[i] += [f\"{m}%, ({lb}, {ub})\"]\n",
    "    \n",
    "    tab = [header] + rows\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(f\"Smoking Prevalences, Status Quo Scenario, {name}\")\n",
    "    printtab(tab)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# same but for CSV readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV values to be read into software\n",
      "All values in this table are percentages\n",
      "Status Quo scenario only, to be compared to BRFSS for validation\n",
      "In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\n",
      "All numbers are rounded to 5 decimal places which should be more than we want for the final table\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/2236342516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{m},\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{lb},\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{ub},\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "print(\"CSV values to be read into software\")\n",
    "print(\"All values in this table are percentages\")\n",
    "print(\"Status Quo scenario only, to be compared to BRFSS for validation\")\n",
    "print(\"In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\")\n",
    "print(\"All numbers are rounded to 5 decimal places which should be more than we want for the final table\")\n",
    "for pop, name in zip([USpop, Bpop], [\"US Population\", \"Black NH Population\"]):\n",
    "\n",
    "    mean_results = np.zeros_like(pop[0])\n",
    "    upper_bound = np.zeros_like(pop[0])\n",
    "    lower_bound = np.zeros_like(pop[0])\n",
    "\n",
    "    for i in range(pop.shape[1]):\n",
    "        for j in range(pop.shape[2]):\n",
    "            mean = np.mean(pop[:,i,j])\n",
    "            upper = np.percentile(pop[:,i,j], 97.5)\n",
    "            lower = np.percentile(pop[:,i,j], 2.5)\n",
    "\n",
    "            mean_results[i,j] = mean\n",
    "            upper_bound[i,j] = upper\n",
    "            lower_bound[i,j] = lower\n",
    "    \n",
    "    # make a table\n",
    "\n",
    "    mean_results = np.around(mean_results * 100, decimals=5)\n",
    "    upper_bound = np.around(upper_bound * 100, decimals=5)\n",
    "    lower_bound = np.around(lower_bound * 100, decimals=5)\n",
    "\n",
    "    header = [\"2016\", \"2017\", \"2021\"]\n",
    "    new_header = [\"group,\"]\n",
    "    for e in header:\n",
    "        new_header.append(e + \"M,\")\n",
    "        new_header.append(e + \"LB,\")\n",
    "        new_header.append(e + \"UB,\") \n",
    "\n",
    "    r1 = [\"NeverSmoker,\"]\n",
    "    r2 = [\"FormerSmoker,\"]\n",
    "    r3 = [\"CigaretteSmoker,\"]\n",
    "    r4 = [\"Ecig/Dual,\"]\n",
    "\n",
    "    rows = [r1, r2, r3, r4]\n",
    "\n",
    "    for i, r in enumerate(rows):\n",
    "        for m, ub, lb in zip(mean_results[:,i], upper_bound[:,i], lower_bound[:,i]):\n",
    "            rows[i] += [f\"{m},\", f\"{lb},\", f\"{ub},\"]\n",
    "    \n",
    "    tab = [new_header] + rows\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(f\"Smoking Prevalences, Status Quo Scenario, {name}\")\n",
    "    print(tabulate(tab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSDUH Validation\n",
    "\n",
    "2016-2020\n",
    "\n",
    "menthol cig use among smokers\n",
    "\n",
    "US pop, black NH, In poverty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status quo\n",
    "outputs = outputs_dirs[0]\n",
    "collection_list = []\n",
    "\n",
    "# for each arr, store a 2D array in the list\n",
    "for f in sorted(glob(outputs + \"/*.npy\")):\n",
    "    arr = np.load(f)\n",
    "    arr = arr[:,:,:,0,:] # age-restrict 18-64\n",
    "    arr = arr[[0, 1, 2, 3, 4]] # get the years we are interested in\n",
    "    arr = arr[:,:,:,:-1] # don't need dead people\n",
    "    collection_list.append(arr)\n",
    "\n",
    "collection_list = np.array(collection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 5, 2, 2, 1, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 4 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/2606618750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUSprops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcollection_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUSprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBprops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcollection_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPprops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcollection_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 4 with size 1"
     ]
    }
   ],
   "source": [
    "USprops = collection_list[:,:,:,:,2].sum(axis=(2,3)) / collection_list[:,:,:,:,2:4].sum(axis=(2,3,4))\n",
    "print(USprops.shape)\n",
    "Bprops = collection_list[:,:,1,:,2].sum(axis=2) / collection_list[:,:,1,:,2:4].sum(axis=(2,3))\n",
    "print(Bprops.shape)\n",
    "Pprops = collection_list[:,:,:,1,2].sum(axis=2) / collection_list[:,:,:,1,2:4].sum(axis=(2,3))\n",
    "print(Pprops.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USprops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/2115445921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m all_props = np.concatenate([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mUSprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mBprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mPprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ], axis=1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'USprops' is not defined"
     ]
    }
   ],
   "source": [
    "all_props = np.concatenate([\n",
    "    USprops[:,np.newaxis,:],\n",
    "    Bprops[:,np.newaxis,:],\n",
    "    Pprops[:,np.newaxis,:],\n",
    "], axis=1)\n",
    "print(all_props.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_props' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/3413924927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlower_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_props\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_props' is not defined"
     ]
    }
   ],
   "source": [
    "mean_results = np.zeros_like(all_props[0])\n",
    "upper_bound = np.zeros_like(all_props[0])\n",
    "lower_bound = np.zeros_like(all_props[0])\n",
    "\n",
    "for i in range(all_props.shape[1]):\n",
    "    for j in range(all_props.shape[2]):\n",
    "        mean = np.mean(all_props[:,i,j])\n",
    "        upper = np.percentile(all_props[:,i,j], 97.5)\n",
    "        lower = np.percentile(all_props[:,i,j], 2.5)\n",
    "\n",
    "        mean_results[i,j] = mean\n",
    "        upper_bound[i,j] = upper\n",
    "        lower_bound[i,j] = lower\n",
    "\n",
    "# make a table\n",
    "\n",
    "mean_results = np.around(mean_results * 100, decimals=1)\n",
    "upper_bound = np.around(upper_bound * 100, decimals=1)\n",
    "lower_bound = np.around(lower_bound * 100, decimals=1)\n",
    "\n",
    "header = [\"\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "\n",
    "r1 = [\"US Population\"]\n",
    "r2 = [\"Black NH\"]\n",
    "r3 = [\"Poverty\"]\n",
    "\n",
    "rows = [r1, r2, r3,]\n",
    "\n",
    "for i, r in enumerate(rows):\n",
    "    for m, ub, lb in zip(mean_results[i], upper_bound[i], lower_bound[i]):\n",
    "        rows[i] += [f\"{m}%, ({lb} {ub})\"]\n",
    "\n",
    "tab = [header] + rows\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(f\"Prevalence of Menthol Cigarette Smoking among Cigarette Smokers, Status Quo Scenario\")\n",
    "printtab(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV values to be read into software\n",
      "All values in this table are percentages\n",
      "Status Quo scenario only, to be compared to NSDUH for validation\n",
      "In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\n",
      "All numbers are rounded to 5 decimal places which should be more than we want for the final table\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_props' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/vrb7dkv56m1g28sspkvsjfjc0000gn/T/ipykernel_12874/1241457288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All numbers are rounded to 5 decimal places which should be more than we want for the final table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmean_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlower_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_props' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"CSV values to be read into software\")\n",
    "print(\"All values in this table are percentages\")\n",
    "print(\"Status Quo scenario only, to be compared to NSDUH for validation\")\n",
    "print(\"In column titles, M = mean, LB = lower bound, UB = upper bound (95% confidence intervals)\")\n",
    "print(\"All numbers are rounded to 5 decimal places which should be more than we want for the final table\")\n",
    "mean_results = np.zeros_like(all_props[0])\n",
    "upper_bound = np.zeros_like(all_props[0])\n",
    "lower_bound = np.zeros_like(all_props[0])\n",
    "\n",
    "for i in range(all_props.shape[1]):\n",
    "    for j in range(all_props.shape[2]):\n",
    "        mean = np.mean(all_props[:,i,j])\n",
    "        upper = np.percentile(all_props[:,i,j], 97.5)\n",
    "        lower = np.percentile(all_props[:,i,j], 2.5)\n",
    "\n",
    "        mean_results[i,j] = mean\n",
    "        upper_bound[i,j] = upper\n",
    "        lower_bound[i,j] = lower\n",
    "\n",
    "# make a table\n",
    "\n",
    "mean_results = np.around(mean_results * 100, decimals=5)\n",
    "upper_bound = np.around(upper_bound * 100, decimals=5)\n",
    "lower_bound = np.around(lower_bound * 100, decimals=5)\n",
    "\n",
    "header = [\"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "new_header = [\"group,\"]\n",
    "for e in header:\n",
    "    new_header.append(e + \"M,\")\n",
    "    new_header.append(e + \"LB,\")\n",
    "    new_header.append(e + \"UB,\") \n",
    "\n",
    "r1 = [\"USPopulation,\"]\n",
    "r2 = [\"BlackPopulation,\"]\n",
    "r3 = [\"PovPopulation,\"]\n",
    "\n",
    "rows = [r1, r2, r3,]\n",
    "\n",
    "for i, r in enumerate(rows):\n",
    "    for m, ub, lb in zip(mean_results[i], upper_bound[i], lower_bound[i]):\n",
    "        rows[i] += [f\"{m},\", f\"{lb},\", f\"{ub},\"]\n",
    "\n",
    "tab = [new_header] + rows\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(f\"Prevalence of Menthol Cigarette Smoking among Cigarette Smokers, Status Quo Scenario\")\n",
    "print(tabulate(tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31397c74860b674650f1d6f64fcb6362844462a9bb9a5172815b4794d002e51b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
